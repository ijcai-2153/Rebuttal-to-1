# Rebuttal

We are most grateful to you for the efficient handling of our paper. We have further clarification for your comments:

- i) The energy function described in 3.3 could be regarded as an elementary way to derive semantic information. However, it is not effective due to the difficulty when determining the semantic coefficient lambda. For example, a large semantic coefficient causes the superpixel segmentation result to adhere to the semantic input, which neglects the color and position knowledge. Due to this reason, in section 3.4, we introduce the semantic label descriptor into the function. The modified function could give the semantic distance a dynamic confidence value. The experiment is implemented with the function in section 3.4.

- ii) We don't use groudtruth annotation to play while computing the difference between the semantic descriptors between two pixels. The sentence "We choose to analyze the relation between semantic descriptors and the ground truth. As demonstrated in Fig. 2, we measured the difference between the highest and second-highest probabilities..." means that we propose multiple candidate forms such as median, standard variance and the difference between the first and second probabilty to ensure the confidence coefficient (i.e., semantic descriptor). In order to select one which is more effective, we compare these semantic descriptors with the groudtruth (as seen in Fig. 2). In summary, the groudtruth helps us determine which descripter we choose rather than the iterating.

- iii) We think that the energy range of the semantic information should be close to the energy range of the traditional information (i.e., color, spatial position), which can reduce the mistake caused by the reason that the error information (e.g., the semantic information is unreliable) has a lot of voice in energy iterations. The role of the rho is to adjust the energy range of the semantic features. The value of the role is found by cross-validation and in our experiment we set rho=120.

- iv) In our paper, AUV = 1 - AEV. AEV quantifies the proximity of the average color of the superpixel to the original color of pixels in the superpixel. A high AEV stands for clustering pixels with same colors into one superpixel, which states that the AEV is an color-oriented metric. To the SLIC and other energy-based, cluster-based methods, a high weight for color term can result in a high AEV easily, but it might be uncorrect to some extent. A correct superpixel needs to be considered multi factors such as color, spatial position, affiliation relationship rather than only regarding the color as the factor, which is beneficial to depth estimation, 3D reconstruction and other post-processings. We introduce the semantic information to superpixels, which gives superpixels logical affiliation relationship. Our method can correct the boundary errors caused by shade, which will suffer a bit on AEV metric yet keep a comparable result on AUV (Ours: 0.099/ SLIC: 0.091).

- v) In our NYU2 experiment, we don't have special points for using this split(1249/100/100). After reviewing other literatures, we find that the benchmark split(795/654) is always used in the learning task with 3D information and there is not a specific description about the split. We expand the training set for two reasons: (i) We think it is enough to use 100 images to evalute methods in our paper. (ii) NYU2 dataset contains many images captured from different viewpoints in the same scene. Expanding training set can reduce the possibility of the overfitting.

- vi) In our opinion, this is uncorrect and incomplete. We think: (i) Superpixels have a wide range of applications in many areas of computer vision, including depth estimation, 3D reconstruction, human pose estimation, tracking, saliency object detection, scene understanding, optical flow and as basis for convolutional neural networks. So it is worth improving the performance of low-level vision tasks using high-level features( e.g., semantic information), which means we can obtain better superpixels and makes the post tasks get better results than before. Generally, we can't be limited to the semantic segmentation task. (ii) Superpixel segmentation and semantic segmentation can be combined as a cooperative task. After several iterations, both of these two tasks may have progress under the help of each other.

- x) We are sorry for these issues. We will correct these mistakes in final version.
